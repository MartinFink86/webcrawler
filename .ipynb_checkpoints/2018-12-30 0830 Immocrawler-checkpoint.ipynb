{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_parameters\n",
    "# get links\n",
    "# get data from links\n",
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "####PRELIMINARIES####\n",
    "\n",
    "#module import#\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "\n",
    "#get current date#\n",
    "current_datetime_master = datetime.datetime.now()\n",
    "current_datetime = current_datetime_master.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "###PARAMETERS\n",
    "#define sub-sites#\n",
    "site_list = [#\"/Wohnung-Miete\",\n",
    "             #\"/Haus-Miete\",\n",
    "             #\"/Wohnung-Kauf\",\n",
    "             \"/Haus-Kauf\",\n",
    "             \"/Grundstueck-Kauf\"]\n",
    "\n",
    "#define top level domain\n",
    "domain=\"https://www.immobilienscout24.de/Suche/S-T\"\n",
    "\n",
    "#define the regions where to look\n",
    "kreis_list = [\"/Bayern/Fuerstenfeldbruck-Kreis\",\n",
    "             \"/Bayern/Dachau-Kreis\"]\n",
    "\n",
    "#initialize dataframe\n",
    "immoscout_data = DataFrame()\n",
    "\n",
    "\n",
    "####EXTRACTING LINKS FOR CRAWLER####\n",
    "\n",
    "#get the last link for every asset type#\n",
    "def get_max(url):\n",
    "    try:\n",
    "        url = urlopen(url)\n",
    "    except:\n",
    "        print(\"Fehler beim Oeffnen der Website\")\n",
    "    try:\n",
    "        site_extract = BeautifulSoup(url.read(), \"lxml\")\n",
    "    except:\n",
    "        print(\"Fehler beim Einlesen in BeautifulSoup\")\n",
    "    try:\n",
    "        max_link = max([int(n[\"value\"]) for n in site_extract.find_all(\"option\")])#get the maximum value for links in a specific sub-site\n",
    "        if max_link is None:\n",
    "            max_link = 0\n",
    "    except:\n",
    "        print(\"Fehler beim Loop\")\n",
    "    else:\n",
    "        return max_link\n",
    "\n",
    "\n",
    "\n",
    "####EXTRACT DATA FROM EVERY SINGLE LINK####\n",
    "def get_data(url):\n",
    "    try:\n",
    "        url_raw = url#save url as string for real estate type\n",
    "        url = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        return None\n",
    "    try:\n",
    "        site_extract = BeautifulSoup(url.read(), \"lxml\")\n",
    "        rawdata_extract = site_extract.find_all(\"div\", {\"class\":\"result-list-entry__data\"})#extract every result box\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    global immoscout_data#use global dataframe\n",
    "    price = []\n",
    "    size = []\n",
    "    location = []\n",
    "    ownership = []\n",
    "    immo_type = []\n",
    "    #print(rawdata_extract)\n",
    "    for i in range(1,len(rawdata_extract)):\n",
    "        try:\n",
    "            price.append(rawdata_extract[i].find_all(\"dd\")[0].get_text().strip())#extract price\n",
    "        except:\n",
    "            price.append(None)\n",
    "        try:\n",
    "            size.append(rawdata_extract[i].find_all(\"dd\")[1].get_text().strip())#extract size\n",
    "        except:\n",
    "            size.append(None)\n",
    "        try:\n",
    "            location.append(rawdata_extract[i].find_all(\"div\", {\"class\":\"result-list-entry__address\"})[0].get_text().strip())#extract location\n",
    "        except:\n",
    "            location.append(None)\n",
    "\n",
    "        if \"/Wohnung\" in url_raw:\n",
    "            immo_type.append(\"Wohnung\")\n",
    "        elif \"/Haus\" in url_raw:\n",
    "            immo_type.append(\"Haus\")\n",
    "        elif \"/Grundstueck\" in url_raw:\n",
    "            immo_type.append(\"Grundstueck\")\n",
    "        else:\n",
    "            immo_type.append(None)\n",
    "\n",
    "        if \"-Miete\" in url_raw:\n",
    "            ownership.append(\"Miete\")\n",
    "        elif \"-Kauf\" in url_raw:\n",
    "            ownership.append(\"Kauf\")\n",
    "        else:\n",
    "            ownership.append(None)\n",
    "    immoscout_data = immoscout_data.append(pd.DataFrame({\"price\":price,\n",
    "                                                  \"size\":size,\n",
    "                                                  \"location\":location,\n",
    "                                                  \"real_estate\":immo_type,\n",
    "                                                  \"ownership\":ownership}),\n",
    "    ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####START CRAWLER####\n",
    "\n",
    "def immo_crawl(site_list:list, kreis_list:list):\n",
    "    max_dict = {}#initialize dictionary for maximum values of links\n",
    "\n",
    "    site_kreis_list = list()\n",
    "    for site in site_list:\n",
    "        for kreis in kreis_list:\n",
    "            site_kreis=site+kreis\n",
    "            site_kreis_list.append(site_kreis)\n",
    "            max_dict[site_kreis] = get_max(domain+site_kreis)#associate maximal link value with specific sub-site\n",
    "\n",
    "    link_list_full = []#initialize list for full links to crawl#\n",
    "    for site_kreis in max_dict:\n",
    "        for i in range(1,max_dict[site_kreis]):\n",
    "            link_list_full.append(domain+\"/P-\"+str(i)+site_kreis)#populate link_list_full\n",
    "    link_count = 1#start for progress indicator\n",
    "\n",
    "    len_link_list_full = len(link_list_full)#end for progress indicator\n",
    "    for link in link_list_full:\n",
    "        print(\"Crawling: \"+link+\" (link #\"+str(link_count)+\" of \"+str(len_link_list_full)+\")\")#print progress\n",
    "        link_count += 1#add to progress indicator\n",
    "        get_data(link)\n",
    "\n",
    "\n",
    "\n",
    "immo_crawl(site_list, kreis_list)#start crawler\n",
    "\n",
    "\n",
    "####PROCESS DATA####\n",
    "\n",
    "immoscout_data.to_csv(\"immoscout_data_raw_\"+current_datetime+\".csv\", sep=\";\", index=False)#export unprocessed data\n",
    "\n",
    "\n",
    "#clean data#\n",
    "def clean_pricesize(data):\n",
    "    data = data.replace(\"€\", \"\")\n",
    "    data = data.replace(\".\", \"\")\n",
    "    data = data.replace(\"m²\", \"\")\n",
    "    data = re.sub(re.compile(\" \\D.*\"), \"\", data)\n",
    "    data = data.strip()\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_firstlayer(data):\n",
    "    fist_layer = data.split(\",\")[0]\n",
    "    return fist_layer.strip()\n",
    "\n",
    "def get_lastlayer(data):\n",
    "    last_layer = data.split(\",\")[-1]\n",
    "    return last_layer.strip()\n",
    "\n",
    "immoscout_data_clean = immoscout_data.dropna(axis=0)\n",
    "immoscout_data_clean[\"price\"] = immoscout_data_clean[\"price\"].apply(clean_pricesize)\n",
    "immoscout_data_clean[\"size\"] = immoscout_data_clean[\"size\"].apply(clean_pricesize)\n",
    "immoscout_data_clean[\"location_first\"] = immoscout_data_clean[\"location\"].apply(get_firstlayer)\n",
    "immoscout_data_clean[\"location_ladsst\"] = immoscout_data_clean[\"location\"].apply(get_lastlayer)\n",
    "\n",
    "immoscout_data_clean[\"crawled\"] = current_datetime_master.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "immoscout_data_clean.to_csv(\"immoscout_data_clean_\"+current_datetime+\".csv\", sep=\";\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp1252-*-\n",
    "\n",
    "####PRELIMINARIES####\n",
    "\n",
    "#module import#\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "class ImmoCrawler:\n",
    "    \n",
    "    def __init__(self,  types_and_regions, domain=\"https://www.immobilienscout24.de/Suche/S-T\"):\n",
    "        \"\"\"Initialize the immo crawler object.\"\"\"\n",
    "                \n",
    "        self._current_datetime = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        self._type_list, self._region_list = types_and_regions        \n",
    "        self._domain = domain\n",
    "        self._data = pd.DataFrame()       \n",
    "        \n",
    "    \n",
    "    def _get_data(self, url):\n",
    "        \"\"\"Get data from link.\"\"\"        \n",
    "        try:\n",
    "            url_raw = url#save url as string for real estate type\n",
    "            url = urlopen(url)\n",
    "        except HTTPError as e:\n",
    "            return None\n",
    "        except URLError as e:\n",
    "            return None\n",
    "        try:\n",
    "            site_extract = BeautifulSoup(url.read(), \"lxml\")\n",
    "            rawdata_extract = site_extract.find_all(\"div\", {\"class\":\"result-list-entry__data\"})#extract every result box\n",
    "        except AttributeError as e:\n",
    "            return None\n",
    "        \n",
    "        price = []\n",
    "        size = []\n",
    "        location = []\n",
    "        ownership = []\n",
    "        immo_type = []\n",
    "        #print(rawdata_extract)\n",
    "        for i in range(1,len(rawdata_extract)):\n",
    "            try:\n",
    "                price.append(rawdata_extract[i].find_all(\"dd\")[0].get_text().strip())#extract price\n",
    "            except:\n",
    "                price.append(None)\n",
    "            try:\n",
    "                size.append(rawdata_extract[i].find_all(\"dd\")[1].get_text().strip())#extract size\n",
    "            except:\n",
    "                size.append(None)\n",
    "            try:\n",
    "                location.append(rawdata_extract[i].find_all(\"div\", {\"class\":\"result-list-entry__address\"})[0].get_text().strip())#extract location\n",
    "            except:\n",
    "                location.append(None)\n",
    "\n",
    "            if \"/Wohnung\" in url_raw:\n",
    "                immo_type.append(\"Wohnung\")\n",
    "            elif \"/Haus\" in url_raw:\n",
    "                immo_type.append(\"Haus\")\n",
    "            elif \"/Grundstueck\" in url_raw:\n",
    "                immo_type.append(\"Grundstueck\")\n",
    "            else:\n",
    "                immo_type.append(None)\n",
    "\n",
    "            if \"-Miete\" in url_raw:\n",
    "                ownership.append(\"Miete\")\n",
    "            elif \"-Kauf\" in url_raw:\n",
    "                ownership.append(\"Kauf\")\n",
    "            else:\n",
    "                ownership.append(None)\n",
    "            \n",
    "        self._data = self._data.append(pd.DataFrame({\"price\":price,\n",
    "                                                  \"size\":size,\n",
    "                                                  \"location\":location,\n",
    "                                                  \"real_estate\":immo_type,\n",
    "                                                  \"ownership\":ownership}),\n",
    "                                    ignore_index=True)            \n",
    "        \n",
    "        \n",
    "    def immo_crawl(self):\n",
    "        \"\"\"Crawl the given sites.\"\"\"\n",
    "        \n",
    "        def get_max(url):\n",
    "            \"\"\"Get the last link for every asset type.\"\"\"\n",
    "            try:\n",
    "                #print ('Trying url', url)\n",
    "                url = urlopen(url)                \n",
    "            except:\n",
    "                print(\"Fehler beim Oeffnen der Website {}\".format(url))\n",
    "            try:\n",
    "                site_extract = BeautifulSoup(url.read(), \"lxml\")\n",
    "            except:\n",
    "                print(\"Fehler beim Einlesen in BeautifulSoup der Website {}\".format(url))            \n",
    "            try:\n",
    "                options_min_max = []\n",
    "                for option in site_extract.find_all(\"option\"):\n",
    "                    options_min_max.append(option[\"value\"])\n",
    "                \n",
    "                if len(options_min_max) == 0:\n",
    "                    options_min_max = [1,1]\n",
    "                else:\n",
    "                    options_min_max = [1, int(options_min_max[-1])]\n",
    "                \n",
    "            except:\n",
    "                print(\"Fehler beim Loop\")            \n",
    "            try:               \n",
    "                link_list = [1, int(options_min_max[1])]                                \n",
    "            except:\n",
    "                print(\"Fehler beim Erstellen der Link Liste:\\n\" + str(link_list))\n",
    "            else:\n",
    "                return link_list   \n",
    "            \n",
    "        \n",
    "        max_dict = {}#initialize dictionary for maximum values of links\n",
    "\n",
    "        site_kreis_list = list()\n",
    "        for site in self._type_list:\n",
    "            for kreis in self._region_list:\n",
    "                site_kreis=site+kreis\n",
    "                site_kreis_list.append(site_kreis)\n",
    "                max_dict[site_kreis] = get_max(domain+site_kreis)#associate maximal link value with specific sub-site\n",
    "                #print(\"For Kreis \", kreis, \"have max_dict\", max_dict)\n",
    "\n",
    "        link_list_full = []#initialize list for full links to crawl#\n",
    "        for site_kreis in max_dict:\n",
    "            #print(\"For Kreis \", kreis, \"have max_dict\", max_dict)\n",
    "            for i in range(1,max_dict[site_kreis][-1]+1):\n",
    "                link_list_full.append(domain+\"/P-\"+str(i)+site_kreis)#populate link_list_full\n",
    "        link_count = 1#start for progress indicator\n",
    "\n",
    "        len_link_list_full = len(link_list_full)#end for progress indicator\n",
    "        for link in link_list_full:\n",
    "            print(\"Crawling: \"+link+\" (link #\"+str(link_count)+\" of \"+str(len_link_list_full)+\")\")#print progress\n",
    "            link_count += 1#add to progress indicator\n",
    "            self._get_data(link)           \n",
    "        \n",
    "\n",
    "    def clean_and_save_data(self):\n",
    "        \"\"\"Clean the data.\"\"\"        \n",
    "        \n",
    "        #self._data.to_csv(\"immoscout_data_raw_\"+self._current_datetime +\".csv\", sep=\";\", index=False)\n",
    "        \n",
    "        def clean_pricesize(data):\n",
    "            data = data.replace(\"€\", \"\")\n",
    "            data = data.replace(\".\", \"\")\n",
    "            data = data.replace(\"m²\", \"\")\n",
    "            data = re.sub(re.compile(\" \\D.*\"), \"\", data)\n",
    "            data = data.strip()\n",
    "            #data = pd.to_numeric(data)            \n",
    "            return data\n",
    "\n",
    "        def get_firstlayer(data):\n",
    "            fist_layer = data.split(\",\")[0]\n",
    "            return fist_layer.strip()\n",
    "\n",
    "        def get_lastlayer(data):\n",
    "            last_layer = data.split(\",\")[-1]\n",
    "            return last_layer.strip()\n",
    "\n",
    "        self._data = self._data.dropna(axis=0)\n",
    "        self._data[\"price\"] = self._data[\"price\"].apply(clean_pricesize)\n",
    "        self._data[\"size\"] = self._data[\"size\"].apply(clean_pricesize)\n",
    "        self._data[\"location_first\"] = self._data[\"location\"].apply(get_firstlayer)\n",
    "        self._data[\"location_last\"] = self._data[\"location\"].apply(get_lastlayer)\n",
    "        self._data[\"crawled\"] = self._current_datetime        \n",
    "        self._data.to_csv(\"immoscout_data_clean_\"+self._current_datetime +\".csv\", sep=\";\", index=False)\n",
    "    \n",
    "    def add_data_to_db(self, db_name = 'immoscout_data_clean_DB.csv'):\n",
    "        \"\"\"Add data to master db.\"\"\"\n",
    "        \n",
    "        df = pd.read_csv(db_name, sep=\";\")\n",
    "        df = df.append(self._data, sort=True)\n",
    "        df = df.drop_duplicates()\n",
    "        df.to_csv(db_name, sep=\";\", index=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define top level domain\n",
    "domain=\"https://www.immobilienscout24.de/Suche/S-T\"\n",
    "\n",
    "types_and_regions = [[#\"/Wohnung-Miete\",\n",
    "             #\"/Haus-Miete\",\n",
    "             #\"/Wohnung-Kauf\",\n",
    "             \"/Haus-Kauf\",\n",
    "             \"/Grundstueck-Kauf\"],\n",
    "            [\"/Bayern/Fuerstenfeldbruck-Kreis\",\n",
    "             \"/Bayern/Dachau-Kreis\",\n",
    "             \"/Bayern/Starnberg-Kreis\",\n",
    "             \"/Bayern/Freising-Kreis\",\n",
    "             \"/Bayern/Erding-Kreis\",\n",
    "             \"/Bayern/Ebersberg-Kreis\",\n",
    "             \"/Bayern/Muenchen-Kreis\",\n",
    "            ]\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #1 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #2 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #3 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #4 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #5 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-6/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #6 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-7/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #7 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-8/Haus-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #8 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Dachau-Kreis (link #9 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Dachau-Kreis (link #10 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Dachau-Kreis (link #11 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Dachau-Kreis (link #12 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Dachau-Kreis (link #13 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Starnberg-Kreis (link #14 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Starnberg-Kreis (link #15 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Starnberg-Kreis (link #16 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Starnberg-Kreis (link #17 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Starnberg-Kreis (link #18 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-6/Haus-Kauf/Bayern/Starnberg-Kreis (link #19 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-7/Haus-Kauf/Bayern/Starnberg-Kreis (link #20 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-8/Haus-Kauf/Bayern/Starnberg-Kreis (link #21 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Freising-Kreis (link #22 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Freising-Kreis (link #23 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Freising-Kreis (link #24 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Freising-Kreis (link #25 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Freising-Kreis (link #26 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Erding-Kreis (link #27 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Erding-Kreis (link #28 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Erding-Kreis (link #29 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Ebersberg-Kreis (link #30 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Ebersberg-Kreis (link #31 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Ebersberg-Kreis (link #32 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Ebersberg-Kreis (link #33 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Ebersberg-Kreis (link #34 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Haus-Kauf/Bayern/Muenchen-Kreis (link #35 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Haus-Kauf/Bayern/Muenchen-Kreis (link #36 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Haus-Kauf/Bayern/Muenchen-Kreis (link #37 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-4/Haus-Kauf/Bayern/Muenchen-Kreis (link #38 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-5/Haus-Kauf/Bayern/Muenchen-Kreis (link #39 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-6/Haus-Kauf/Bayern/Muenchen-Kreis (link #40 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-7/Haus-Kauf/Bayern/Muenchen-Kreis (link #41 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-8/Haus-Kauf/Bayern/Muenchen-Kreis (link #42 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-9/Haus-Kauf/Bayern/Muenchen-Kreis (link #43 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-10/Haus-Kauf/Bayern/Muenchen-Kreis (link #44 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-11/Haus-Kauf/Bayern/Muenchen-Kreis (link #45 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-12/Haus-Kauf/Bayern/Muenchen-Kreis (link #46 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #47 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Grundstueck-Kauf/Bayern/Fuerstenfeldbruck-Kreis (link #48 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Dachau-Kreis (link #49 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Grundstueck-Kauf/Bayern/Dachau-Kreis (link #50 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Starnberg-Kreis (link #51 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Grundstueck-Kauf/Bayern/Starnberg-Kreis (link #52 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Freising-Kreis (link #53 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Grundstueck-Kauf/Bayern/Freising-Kreis (link #54 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Erding-Kreis (link #55 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Ebersberg-Kreis (link #56 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-1/Grundstueck-Kauf/Bayern/Muenchen-Kreis (link #57 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-2/Grundstueck-Kauf/Bayern/Muenchen-Kreis (link #58 of 59)\n",
      "Crawling: https://www.immobilienscout24.de/Suche/S-T/P-3/Grundstueck-Kauf/Bayern/Muenchen-Kreis (link #59 of 59)\n"
     ]
    }
   ],
   "source": [
    "session = ImmoCrawler(types_and_regions)\n",
    "session.immo_crawl()\n",
    "session.clean_and_save_data()\n",
    "session._data\n",
    "session.add_data_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_data_to_db()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
